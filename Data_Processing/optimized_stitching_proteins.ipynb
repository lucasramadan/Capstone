{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:48:45.842102",
     "start_time": "2016-06-14T12:48:36.900497"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:49:42.506889",
     "start_time": "2016-06-14T12:49:42.501755"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = [[1, 2, 3, 4], \n",
    "      [5, 6, 7, 8]]\n",
    "\n",
    "l2 = [[9, 10, 11, 12], \n",
    "      [13, 14, 15, 16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:50:11.363519",
     "start_time": "2016-06-14T12:50:11.351206"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(l1+l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy Concatenate is the fastest (Append uses Concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:51:12.033964",
     "start_time": "2016-06-14T12:51:11.952629"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = pd.read_csv('../clean_dssp_csv/1a3n.csv')\n",
    "\n",
    "f2 = pd.read_csv('../clean_dssp_csv/1b3n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:58:26.049065",
     "start_time": "2016-06-14T12:58:22.340654"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 885 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.concatenate((f1.values, f2.values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:59:20.344830",
     "start_time": "2016-06-14T12:59:16.575576"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 889 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.append(f1.values, f2.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:55:07.983971",
     "start_time": "2016-06-14T12:55:02.075132"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.41 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "f1.values.tolist() + f2.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T12:55:49.196114",
     "start_time": "2016-06-14T12:55:46.125311"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.04 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "f1.append(f2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacing = [11, 13, 15, 17, 19, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T13:03:56.349066",
     "start_time": "2016-06-14T13:03:19.488080"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topdir, _, files = next(os.walk('/Volumes/DSSP/Capstone/clean_dssp_csv/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T13:04:05.109162",
     "start_time": "2016-06-14T13:04:05.102463"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116176"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new spacing\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-14T13:04:47.565634",
     "start_time": "2016-06-14T13:04:47.552435"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original spacing\n",
    "len(next(os.walk('../clean_dssp_csv/'))[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(files)\n",
    "\n",
    "# outer for each spacing\n",
    "for i, s in enumerate(spacing):\n",
    "\n",
    "    rel_files = files[(n*i):(n*(i+1))]\n",
    "    \n",
    "    # for matrices\n",
    "    combo = pd.read_csv(topdir+rel_files[0])\n",
    "    header = combo.columns \n",
    "    combo = combo.values\n",
    "\n",
    "#     for tensors\n",
    "#     combo = np.load(topdir+rel_files[0])\n",
    "    \n",
    "    # inner for each file after\n",
    "    for ii, rf in enumerate(rel_files[1:]):\n",
    "        \n",
    "        prog = (ii+1) + (i*347)\n",
    "        print('\\rprogress: ' + str(int(prog*100.0/(n-1))) + '%', end='')\n",
    "        \n",
    "        # for matrices\n",
    "        df = pd.read_csv(topdir+rf)\n",
    "        combo = np.concatenate((combo, df.values), axis=0)\n",
    "        \n",
    "#         # for tensors\n",
    "#         d = np.load(topdir+rf)\n",
    "#         combo = np.append(combo, d, axis=0)\n",
    "\n",
    "    # for matrices, write the combo\n",
    "    fn = '../combined_verbose_dssp_csv/(' + str(s) + ')_combined_verbose.csv'\n",
    "    combo = pd.DataFrame(combo, columns=header)\n",
    "    combo.to_csv(fn, index=False)\n",
    "\n",
    "#     # for tensors write the combo\n",
    "#     fn = '../combined_scaled_tensor_dssp_npy/(' + str(s) + ')_combined_scaled.npy'\n",
    "#     np.save(fn, combo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
